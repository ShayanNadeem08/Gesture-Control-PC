{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "modules_path = 'C:/Users/PMLS/FYP/Modules/'\n",
    "dataset_path = 'C:/Users/PMLS/FYP/Dataset/STMM'\n",
    "save_path = \"C:/Users/PMLS/FYP/Models\"\n",
    "\n",
    "sys.path.insert(1, modules_path)\n",
    "from video_dataset import VideoFrameDataset, ImglistToTensor\n",
    "\n",
    "if False and torch.xpu.is_available():\n",
    "    device = torch.device(\"xpu\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "B\n",
      "C\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class MLE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLE, self).__init__()\n",
    "        print(\"A\")\n",
    "        self.layer0 = torch.nn.LSTM(2,2)\n",
    "        print(\"B\")\n",
    "        self.layer1 = torch.nn.Linear(2,5)\n",
    "        print(\"C\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        out0 = self.layer0(x)\n",
    "        out1 = self.layer1(out0)\n",
    "        return out1\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "model = MLE().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training loop\n",
    "def train(model, data):\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(data):\n",
    "        print(x)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_hat = model(x)\n",
    "        loss = loss_function(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "\n",
    "def test(model, data, label=\"\"):\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (x,y) in enumerate(data):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_hat = model(x)\n",
    "            _, y_hat = torch.max(y_hat,1)\n",
    "            correct += (y_hat==y).sum()\n",
    "    print(label+\"accuracy:\", round(float(correct/(i+1)/batch_size), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "GESTURE_MAP_STR2NUM = {'down': 0, 'left': 1, 'right': 2, 'up': 3, \"none\":4}\n",
    "def get_dataset(N):\n",
    "    dataset = []\n",
    "    for i in range(N):\n",
    "        # res = 64*np.random.rand(21,2)\n",
    "        # prev_res = 64*np.random.rand(21,2)\n",
    "        \n",
    "        # dresults = res-prev_res\n",
    "        # dX, dY = np.mean(dresults,0)\n",
    "        dX, dY = np.random.randn(2,1) * 32\n",
    "\n",
    "        if abs(dX) < epsilon and abs(dY) < epsilon:\n",
    "            prediction_result = \"none\"\n",
    "        elif abs(dX) > abs(dY):\n",
    "            if dX > 0:\n",
    "                prediction_result=\"left\"\n",
    "            else:\n",
    "                prediction_result=\"right\"\n",
    "        elif abs(dX) < abs(dY):\n",
    "            if dY > 0:\n",
    "                prediction_result=\"down\"\n",
    "            else:\n",
    "                prediction_result=\"up\"\n",
    "        else:\n",
    "            prediction_result = \"none\"\n",
    "\n",
    "        data = torch.from_numpy(np.array([dX[0],dY[0]]).astype(np.float32))\n",
    "        label = torch.tensor(GESTURE_MAP_STR2NUM[prediction_result])\n",
    "        dataset.append([data, label])\n",
    "    return dataset\n",
    "\n",
    "epsilon = 1\n",
    "dataset = get_dataset(18400)\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "train_dataset, test_dataset = random_split(dataset, [0.5,0.5])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:4\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PMLS\\FYP\\Gesture-Control-PC\\codes_old\\rule.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_hat \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(y_hat, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[1;32mc:\\Users\\PMLS\\FYP\\Gesture-Control-PC\\codes_old\\rule.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     out0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer0(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     out1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(out0)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/PMLS/FYP/Gesture-Control-PC/codes_old/rule.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out1\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not tuple"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train\n",
    "N=40\n",
    "for epoch in range(N):\n",
    "    loss = train(model, train_loader)\n",
    "print(\"loss =\", loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.994\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../model/MLE.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
